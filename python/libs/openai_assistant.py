import openai
import time
import os
import sys
import json
import re
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

sys.path.append(os.path.dirname(__file__))
import prompt_templates as pt

# è®¾ç½® OpenAI API å¯†é’¥
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL")

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
client = openai.OpenAI(api_key=OPENAI_API_KEY)

def clean_text(text: str) -> str:
    """
    è¿‡æ»¤æ‰ file_search ç»“æœä¸­çš„ã€x:yâ€ sourceã€‘æ ¼å¼çš„å¼•ç”¨ä¿¡æ¯
    """
    return re.sub(r"ã€\d+:\d+â€ sourceã€‘", "", text).strip()

def create_vector_store_with_file(library_data_path: str) -> str:
    """
    1. åˆ›å»ºä¸€ä¸ªæ–°çš„ vector store
    2. ä¸Šä¼ æœ¬åœ°ä¹¦ç±æ•°æ®åº“æ–‡ä»¶
    3. å…³è”æ–‡ä»¶åˆ° vector store
    4. è¿”å› vector store ID
    """
    # åˆ›å»º vector store
    vector_store = client.vector_stores.create(name="Library Vector Store")
    vector_store_id = vector_store.id
    print(f"ğŸ“ Created vector store with ID: {vector_store_id}")

    # ä¸Šä¼ æ–‡ä»¶å¹¶å…³è”åˆ° vector store
    with open(library_data_path, "rb") as file:
        uploaded_file = client.files.create(file=file, purpose="assistants")
        file_id = uploaded_file.id
        print(f"ğŸ“„ Uploaded file with ID: {file_id}")

    # å…³è”æ–‡ä»¶åˆ° vector store
    client.vector_stores.files.create(vector_store_id=vector_store_id, file_id=file_id)
    print(f"âœ… Linked file to vector store {vector_store_id}")

    return vector_store_id


def ensure_assistant(library_data_path: str) -> str:
    """
    ç¡®ä¿å­˜åœ¨ä¸€ä¸ª Assistantï¼Œè‹¥æ— åˆ™åˆ›å»ºï¼Œå¹¶è¿”å› assistant_idï¼Œ
    åŒæ—¶ä¸Šä¼ æœ¬åœ°å‚è€ƒæ–‡ä»¶åˆ° Vector Store å¹¶å¯ç”¨æ–‡ä»¶æœç´¢å·¥å…·ã€‚
    """
    vector_store_id = create_vector_store_with_file(library_data_path)

    assistant = client.beta.assistants.create(
        name="Book Recommender",
        instructions=pt.OPENAI_ASSISTANT_INSTRUCTION,
        model=OPENAI_MODEL,
        tools=[
            {"type": "file_search"},  # å¯ç”¨æ–‡ä»¶æœç´¢å·¥å…·
            {
                "type": "function",
                "function": {
                    "name": "recommend_books",
                    "description": pt.OPENAI_ANALYSIS_FUNCTION_DESCRIPTION,
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "recommendation_summary": {
                                "type": "string",
                                "description": pt.OPENAI_ANALYSIS_FUNCTION_RESULT_DESCRIPTION
                            },
                            "recommended_books": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "book_id": {"type": "string", "description": "book_id in the Library Vector Store"},
                                        "book_title": {"type": "string", "description": "book_title in the Library Vector Store"},
                                        "reason": {"type": "string", "description": "Reason for recommendation"}
                                    }
                                },
                                "description": "æ¨èçš„ä¹¦ç±ï¼ŒåŒ…æ‹¬ä¹¦ç±çš„ book_id, book_title, å’Œæ¨èç†ç”±"
                            }
                        },
                        "required": ["recommendation_summary", "recommended_books"]
                    }
                }
            }
        ],
        tool_resources={"file_search": {"vector_store_ids": [vector_store_id]}}  # å…³è” vector store
    )

    print(f"âœ… Assistant created with ID: {assistant.id}")
    return assistant.id



def analyze_user_interest(assistant_id: str, user_data: str) -> str:
    """
    å…ˆåˆ†æç”¨æˆ·çš„é˜…è¯»è®°å½•ï¼Œè¿”å›ç”¨æˆ·å…´è¶£æ‘˜è¦ (recommendation_summary)
    """
    thread = client.beta.threads.create()
    print(f"ğŸ“Œ Thread created with ID: {thread.id}")

    user_prompt = pt.OPENAI_USER_INTEREST_ANALYSIS_PROMPT.format(reading_hisory=user_data)
    print(f"ğŸ“© User Prompt:\n{user_prompt}")

    client.beta.threads.messages.create(
        thread_id=thread.id,
        role="user",
        content=user_prompt
    )

    run = client.beta.threads.runs.create(
        thread_id=thread.id,
        assistant_id=assistant_id
    )

    print("â³ Running Assistant for User Interest Analysis...")

    recommendation_summary = ""

    while True:
        run_status = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)
        print(f"ğŸ”„ Status: {run_status.status}")

        if run_status.status in ["completed", "failed", "cancelled"]:
            break

        if run_status.status == "requires_action":
            if hasattr(run_status.required_action, "submit_tool_outputs"):
                tool_calls = run_status.required_action.submit_tool_outputs.tool_calls

                for tool_call in tool_calls:
                    if hasattr(tool_call, "function"):
                        function_name = getattr(tool_call.function, "name", "")
                        function_args = json.loads(getattr(tool_call.function, "arguments", "{}"))

                        if function_name == "recommend_books":
                            recommendation_summary = function_args.get("recommendation_summary", "")

                            client.beta.threads.runs.submit_tool_outputs(
                                thread_id=thread.id,
                                run_id=run.id,
                                tool_outputs=[
                                    {
                                        "tool_call_id": tool_call.id,
                                        "output": json.dumps({
                                            "recommendation_summary": recommendation_summary
                                        })
                                    }
                                ]
                            )

                            print("âœ… Interest analysis complete.")
                            continue
        time.sleep(2)

    if run_status.status != "completed":
        print("âŒ Assistant run failed.")
        return ""

    return recommendation_summary

def search_books_by_interest(assistant_id: str, user_data: str) -> list:
    """
    ä½¿ç”¨ file_search æŸ¥è¯¢ Vector Storeï¼Œæ‰¾åˆ°åŒ¹é…çš„ä¹¦ç±
    """
    thread = client.beta.threads.create()
    print(f"ğŸ“Œ Thread created with ID: {thread.id}")

    print(f"ğŸ” Searching related books:")
    user_prompt = pt.OPENAI_USER_RECOOMMANDATION_PROMPT.format(reading_hisory=user_data)

    client.beta.threads.messages.create(
        thread_id=thread.id,
        role="user",
        content=user_prompt
    )
    run = client.beta.threads.runs.create(
        thread_id=thread.id,
        assistant_id=assistant_id,
        tool_choice={"type": "file_search"},
    )

    recommended_books = []

    while True:
        run_status = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)
        print(f"ğŸ”„ Status: {run_status.status}")

        if run_status.status in ["completed", "failed", "cancelled"]:
            break

        if run_status.status == "requires_action":
            if hasattr(run_status.required_action, "submit_tool_outputs"):
                tool_calls = run_status.required_action.submit_tool_outputs.tool_calls

                for tool_call in tool_calls:
                    if hasattr(tool_call, "function"):
                        function_name = getattr(tool_call.function, "name", "")
                        function_args = json.loads(getattr(tool_call.function, "arguments", "{}"))

                        if function_name == "recommend_books":
                            recommended_books = function_args.get("recommended_books", [])

                            # âœ… è¿‡æ»¤æ‰ä¹¦ç±æ¨èç†ç”±ä¸­çš„ã€x:yâ€ sourceã€‘å¼•ç”¨ä¿¡æ¯
                            for book in recommended_books:
                                book["reason"] = clean_text(book["reason"])  # å»é™¤å¼•ç”¨ä¿¡æ¯
                                book["book_title"] = clean_text(book["book_title"])  # é¿å…æ ‡é¢˜ä¸­ä¹Ÿå¸¦æœ‰å¼•ç”¨

                            client.beta.threads.runs.submit_tool_outputs(
                                thread_id=thread.id,
                                run_id=run.id,
                                tool_outputs=[
                                    {
                                        "tool_call_id": tool_call.id,
                                        "output": json.dumps({
                                            "recommended_books": recommended_books
                                        })
                                    }
                                ]
                            )

                            print("âœ… Book recommendation complete.")
                            continue
        time.sleep(2)

    if run_status.status != "completed":
        print("âŒ Assistant run failed.")
        return []

    return recommended_books


def delete_assistant(assistant_id: str):
    """
    åˆ é™¤ Assistantï¼ŒåŒæ—¶åˆ é™¤ file_search å…³è”çš„ vector store åŠå…¶æ–‡ä»¶
    """
    try:
        # 1ï¸âƒ£ è·å– Assistant è¯¦ç»†ä¿¡æ¯
        assistant = client.beta.assistants.retrieve(assistant_id)

        # 2ï¸âƒ£ è·å– `file_search` å…³è”çš„ `vector_store` IDï¼ˆä½¿ç”¨æ­£ç¡®çš„è®¿é—®æ–¹å¼ï¼‰
        vector_store_ids = assistant.tool_resources.file_search.vector_store_ids if assistant.tool_resources.file_search else []

        print(f"ğŸ“Œ Found {len(vector_store_ids)} vector store(s) linked to Assistant {assistant_id}: {vector_store_ids}")

        # 3ï¸âƒ£ åˆ é™¤ Assistant
        client.beta.assistants.delete(assistant_id)
        print(f"ğŸ—‘ï¸ Assistant {assistant_id} deleted.")

        # 4ï¸âƒ£ åˆ é™¤ `vector_store` åŠå…¶å…³è”çš„æ–‡ä»¶
        for vector_store_id in vector_store_ids:
            try:
                # è·å– vector store å…³è”çš„æ–‡ä»¶
                vector_store_files = client.vector_stores.files.list(vector_store_id=vector_store_id)

                # åˆ é™¤æ‰€æœ‰æ–‡ä»¶
                for file in vector_store_files.data:
                    client.vector_stores.files.delete(vector_store_id=vector_store_id, file_id=file.id)
                    print(f"ğŸ—‘ï¸ Deleted file {file.id} from vector store {vector_store_id}")

                # åˆ é™¤ vector store
                client.vector_stores.delete(vector_store_id)
                print(f"ğŸ—‘ï¸ Deleted vector store {vector_store_id}")

            except Exception as e:
                print(f"âš ï¸ Failed to delete vector store {vector_store_id}: {e}")

    except Exception as e:
        print(f"âŒ Error deleting assistant {assistant_id}: {e}")

# è°ƒç”¨ç¤ºä¾‹
if __name__ == "__main__":
    library_data_path = "library_books.txt"  # ä½ çš„æœ¬åœ°å›¾ä¹¦æ•°æ®æ–‡ä»¶
    assistant_id = ensure_assistant(library_data_path)

    user_data = """Reading time: 2024-03-10\nBook Title: The Science of Space\nBook Description: An introduction to astrophysics and space exploration."""
    summary, books = analyze_user_data(assistant_id, user_data)

    print(f"\nğŸ“– Recommended Books:")
    for book in books:
        print(f"ğŸ“Œ Book ID: {book['book_id']} - Reason: {book['reason']}")